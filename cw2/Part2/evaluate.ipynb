{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import *\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pred.out', 'r', encoding='utf-8') as p:\n",
    "    pred = [p.replace('\\n', '') for p in p.readlines()]\n",
    "with open('feats.test', 'r', encoding='utf-8') as t:\n",
    "    ref = [t.replace('\\n', '') for t in t.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = []\n",
    "for i in range(len(pred)):\n",
    "    pred_labels.append(re.findall(r'^([0-9]+?) ', pred[i])[0])\n",
    "    \n",
    "ref_labels = []\n",
    "for i in range(len(ref)):\n",
    "    ref_labels.append(re.findall(r'^([0-9]+?) ', ref[i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_labels</th>\n",
       "      <th>ref_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pred_labels ref_labels\n",
       "0           7         11\n",
       "1           8          8\n",
       "2           9          9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['pred_labels', 'ref_labels'])\n",
    "df['pred_labels'] = pred_labels\n",
    "df['ref_labels'] = ref_labels\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6656"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_acc = np.sum(df['pred_labels'] == df['ref_labels']) / len(df)\n",
    "_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_num_pred = dict()\n",
    "class_to_num_ref = dict()\n",
    "for cl in range(1, 15):\n",
    "    class_to_num_pred[cl] = list(df['pred_labels'][(df['pred_labels'].astype(int) == cl)].index)\n",
    "    class_to_num_ref[cl] = list(df['ref_labels'][(df['ref_labels'].astype(int) == cl)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(class_num, total):\n",
    "    _pred = class_to_num_pred[class_num]\n",
    "    _ref = class_to_num_ref[class_num]\n",
    "    TP = 0\n",
    "    for ind in _pred:\n",
    "        if ind in _ref:\n",
    "            TP += 1\n",
    "    FN = len(_ref) - TP\n",
    "    FP = len(_pred) - TP\n",
    "    TN = (total - len(_pred)) - FN\n",
    "    assert (total - len(_pred)) - FN == (total - len(_ref)) - FP\n",
    "    \n",
    "#     print('TP: {}, FP: {}\\n'.format(TP, FP) +\n",
    "#           'FN: {}, TN: {}'.format(FN, TN))\n",
    "    \n",
    "    acc = (TP + TN) / float(total)\n",
    "    P = TP / float(TP + FP)\n",
    "    R = TP / float(TP + FN)\n",
    "    F1 = (2 * P * R) / float(P + R) \n",
    "    \n",
    "    return acc, P, R, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9632, 0.71875, 0.9019607843137255, 0.8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(1, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_F1 = 0\n",
    "for i in range(1, 15):\n",
    "    _, _, _, F1 = evaluate(i, len(df))\n",
    "    m_F1 += F1\n",
    "m_F1 = m_F1 / float(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Eval.txt', 'w+', encoding='utf-8') as e:\n",
    "    e.write('Accuracy = ' + str(round(_acc, 3)) + '\\n')\n",
    "    e.write('Macro-F1 = ' + str(round(m_F1, 3)) + '\\n')\n",
    "    e.write('Results per class:\\n')\n",
    "    for i in range(1, 15):\n",
    "        _, P, R, F1 = evaluate(i, len(df))\n",
    "        e.write('{}: P={} R={} F={}'.format(i, round(P, 3), round(R, 3), round(F1, 3)) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
